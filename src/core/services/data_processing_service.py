"""æ•¸æ“šè™•ç†æœå‹™

æä¾›æ•¸æ“šåˆ†æã€èšåˆå’Œè½‰æ›åŠŸèƒ½ã€‚
"""

import logging
import pandas as pd
from datetime import datetime, date, timedelta
from typing import List, Dict, Any, Optional, Tuple
from pathlib import Path
from statistics import mean, median, stdev
from collections import defaultdict

from ..models.gpu import GPU
from ..models.node import Node
from ..models.user import User
from ...infrastructure.config.settings import AppConfig


logger = logging.getLogger(__name__)


class DataProcessingService:
    """æ•¸æ“šè™•ç†æœå‹™
    
    æä¾›æ•¸æ“šæ¸…ç†ã€åˆ†æã€èšåˆå’Œçµ±è¨ˆåŠŸèƒ½ã€‚
    """
    
    def __init__(self, config: AppConfig):
        self.config = config
    
    def load_node_data(self, 
                       node_name: str, 
                       target_date: date) -> Optional[Dict[str, Any]]:
        """è¼‰å…¥ç¯€é»æ•¸æ“š
        
        Args:
            node_name: ç¯€é»åç¨±
            target_date: ç›®æ¨™æ—¥æœŸ
            
        Returns:
            ç¯€é»æ•¸æ“šå­—å…¸æˆ– None
        """
        date_str = target_date.isoformat()
        node_dir = self.config.data_dir / node_name / date_str
        
        if not node_dir.exists():
            logger.warning(f"ç¯€é»æ•¸æ“šç›®éŒ„ä¸å­˜åœ¨: {node_dir}")
            return None
        
        node_data = {
            'node_name': node_name,
            'date': date_str,
            'gpu_data': {},
            'averages': None
        }
        
        # è¼‰å…¥ GPU æ•¸æ“š
        for gpu_index in self.config.gpu.indices:
            gpu_file = node_dir / f"gpu{gpu_index}_{date_str}.csv"
            vram_file = node_dir / f"gpu{gpu_index}_vram_{date_str}.csv"
            
            gpu_data = {}
            
            # è¼‰å…¥ GPU ä½¿ç”¨ç‡
            if gpu_file.exists():
                gpu_data['utilization'] = self._load_csv_data(gpu_file)
            
            # è¼‰å…¥ VRAM ä½¿ç”¨ç‡
            if vram_file.exists():
                gpu_data['vram'] = self._load_csv_data(vram_file)
            
            if gpu_data:
                node_data['gpu_data'][f'gpu{gpu_index}'] = gpu_data
        
        # è¼‰å…¥å¹³å‡å€¼
        avg_file = node_dir / f"average_{date_str}.csv"
        if avg_file.exists():
            node_data['averages'] = self._load_average_data(avg_file)
        
        return node_data
    
    def load_multi_node_data(self, 
                            nodes: List[str], 
                            start_date: date,
                            end_date: date) -> Dict[str, Dict[str, Any]]:
        """è¼‰å…¥å¤šç¯€é»å¤šæ—¥æœŸæ•¸æ“š
        
        Args:
            nodes: ç¯€é»åç¨±åˆ—è¡¨
            start_date: é–‹å§‹æ—¥æœŸ
            end_date: çµæŸæ—¥æœŸ
            
        Returns:
            æŒ‰ç¯€é»å’Œæ—¥æœŸçµ„ç¹”çš„æ•¸æ“š
        """
        all_data = defaultdict(dict)
        
        current_date = start_date
        while current_date <= end_date:
            for node_name in nodes:
                node_data = self.load_node_data(node_name, current_date)
                if node_data:
                    all_data[node_name][current_date.isoformat()] = node_data
            
            current_date += timedelta(days=1)
        
        return dict(all_data)
    
    def calculate_node_statistics(self, 
                                 node_data: Dict[str, Any]) -> Dict[str, Any]:
        """è¨ˆç®—ç¯€é»çµ±è¨ˆè³‡è¨Š
        
        Args:
            node_data: ç¯€é»æ•¸æ“š
            
        Returns:
            çµ±è¨ˆè³‡è¨Šå­—å…¸
        """
        stats = {
            'node_name': node_data['node_name'],
            'date': node_data['date'],
            'gpu_count': len(node_data['gpu_data']),
            'gpu_stats': {},
            'node_total': {
                'avg_utilization': 0,
                'avg_vram': 0,
                'max_utilization': 0,
                'max_vram': 0,
                'min_utilization': 100,
                'min_vram': 100
            }
        }
        
        utilization_values = []
        vram_values = []
        
        # ç‚ºæ¯å€‹ GPU è¨ˆç®—çµ±è¨ˆ
        for gpu_key, gpu_data in node_data['gpu_data'].items():
            gpu_stats = self._calculate_gpu_statistics(gpu_data)
            stats['gpu_stats'][gpu_key] = gpu_stats
            
            if gpu_stats['utilization']:
                utilization_values.extend(gpu_stats['utilization']['values'])
                vram_values.extend(gpu_stats['vram']['values'])
        
        # è¨ˆç®—ç¯€é»ç¸½é«”çµ±è¨ˆ
        if utilization_values:
            stats['node_total']['avg_utilization'] = mean(utilization_values)
            stats['node_total']['max_utilization'] = max(utilization_values)
            stats['node_total']['min_utilization'] = min(utilization_values)
        
        if vram_values:
            stats['node_total']['avg_vram'] = mean(vram_values)
            stats['node_total']['max_vram'] = max(vram_values)
            stats['node_total']['min_vram'] = min(vram_values)
        
        return stats
    
    def calculate_multi_node_summary(self,
                                   multi_node_data: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
        """è¨ˆç®—å¤šç¯€é»æ‘˜è¦çµ±è¨ˆ
        
        Args:
            multi_node_data: å¤šç¯€é»æ•¸æ“š
            
        Returns:
            æ‘˜è¦çµ±è¨ˆå­—å…¸
        """
        summary = {
            'total_nodes': len(multi_node_data),
            'date_range': {},
            'node_summaries': {},
            'overall_stats': {
                'avg_utilization': 0,
                'avg_vram': 0,
                'total_data_points': 0,
                'active_gpus': 0
            }
        }
        
        all_utilization = []
        all_vram = []
        all_dates = set()
        total_gpus = 0
        
        # è™•ç†æ¯å€‹ç¯€é»çš„æ•¸æ“š
        for node_name, node_dates in multi_node_data.items():
            node_summary = {
                'dates': list(node_dates.keys()),
                'total_days': len(node_dates),
                'avg_utilization': 0,
                'avg_vram': 0
            }
            
            node_utilization = []
            node_vram = []
            
            for date_str, node_data in node_dates.items():
                all_dates.add(date_str)
                stats = self.calculate_node_statistics(node_data)
                
                node_utilization.append(stats['node_total']['avg_utilization'])
                node_vram.append(stats['node_total']['avg_vram'])
                total_gpus += stats['gpu_count']
            
            if node_utilization:
                node_summary['avg_utilization'] = mean(node_utilization)
                node_summary['avg_vram'] = mean(node_vram)
                all_utilization.extend(node_utilization)
                all_vram.extend(node_vram)
            
            summary['node_summaries'][node_name] = node_summary
        
        # è¨ˆç®—æ•´é«”çµ±è¨ˆ
        if all_utilization:
            summary['overall_stats']['avg_utilization'] = mean(all_utilization)
        if all_vram:
            summary['overall_stats']['avg_vram'] = mean(all_vram)
        
        summary['overall_stats']['active_gpus'] = total_gpus
        summary['overall_stats']['total_data_points'] = len(all_utilization)
        
        # è¨­å®šæ—¥æœŸç¯„åœ
        if all_dates:
            sorted_dates = sorted(all_dates)
            summary['date_range'] = {
                'start': sorted_dates[0],
                'end': sorted_dates[-1],
                'total_days': len(sorted_dates)
            }
        
        return summary
    
    def find_peak_usage_periods(self,
                               node_data: Dict[str, Any],
                               threshold: float = 80.0) -> List[Dict[str, Any]]:
        """å°‹æ‰¾é«˜ä½¿ç”¨ç‡æ™‚æ®µ
        
        Args:
            node_data: ç¯€é»æ•¸æ“š
            threshold: ä½¿ç”¨ç‡é–¾å€¼
            
        Returns:
            é«˜ä½¿ç”¨ç‡æ™‚æ®µåˆ—è¡¨
        """
        peak_periods = []
        
        for gpu_key, gpu_data in node_data['gpu_data'].items():
            if 'utilization' not in gpu_data:
                continue
            
            utilization_data = gpu_data['utilization']
            current_period = None
            
            for timestamp, value in utilization_data:
                if value >= threshold:
                    if current_period is None:
                        current_period = {
                            'gpu': gpu_key,
                            'start_time': timestamp,
                            'end_time': timestamp,
                            'max_usage': value,
                            'avg_usage': value,
                            'values': [value]
                        }
                    else:
                        current_period['end_time'] = timestamp
                        current_period['values'].append(value)
                        current_period['max_usage'] = max(current_period['max_usage'], value)
                        current_period['avg_usage'] = mean(current_period['values'])
                else:
                    if current_period is not None:
                        # è¨ˆç®—æŒçºŒæ™‚é–“
                        duration = current_period['end_time'] - current_period['start_time']
                        current_period['duration_minutes'] = duration / 60
                        
                        peak_periods.append(current_period)
                        current_period = None
            
            # è™•ç†æœ€å¾Œä¸€å€‹æ™‚æ®µ
            if current_period is not None:
                duration = current_period['end_time'] - current_period['start_time']
                current_period['duration_minutes'] = duration / 60
                peak_periods.append(current_period)
        
        # æŒ‰æŒçºŒæ™‚é–“æ’åº
        peak_periods.sort(key=lambda x: x['duration_minutes'], reverse=True)
        
        return peak_periods
    
    def generate_usage_report(self,
                            multi_node_data: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
        """ç”Ÿæˆä½¿ç”¨ç‡å ±å‘Š
        
        Args:
            multi_node_data: å¤šç¯€é»æ•¸æ“š
            
        Returns:
            ä½¿ç”¨ç‡å ±å‘Š
        """
        report = {
            'generation_time': datetime.now().isoformat(),
            'summary': self.calculate_multi_node_summary(multi_node_data),
            'node_details': {},
            'recommendations': []
        }
        
        # ç‚ºæ¯å€‹ç¯€é»ç”Ÿæˆè©³ç´°å ±å‘Š
        for node_name, node_dates in multi_node_data.items():
            node_details = {
                'daily_stats': {},
                'peak_periods': [],
                'trends': {}
            }
            
            daily_utilization = []
            daily_vram = []
            
            for date_str, node_data in node_dates.items():
                stats = self.calculate_node_statistics(node_data)
                node_details['daily_stats'][date_str] = stats
                
                daily_utilization.append(stats['node_total']['avg_utilization'])
                daily_vram.append(stats['node_total']['avg_vram'])
                
                # å°‹æ‰¾é«˜ä½¿ç”¨ç‡æ™‚æ®µ
                peaks = self.find_peak_usage_periods(node_data)
                node_details['peak_periods'].extend(peaks)
            
            # è¨ˆç®—è¶¨å‹¢
            if len(daily_utilization) > 1:
                node_details['trends'] = {
                    'utilization_trend': self._calculate_trend(daily_utilization),
                    'vram_trend': self._calculate_trend(daily_vram)
                }
            
            report['node_details'][node_name] = node_details
        
        # ç”Ÿæˆå»ºè­°
        report['recommendations'] = self._generate_recommendations(report)
        
        return report
    
    def _load_csv_data(self, csv_file: Path) -> List[Tuple[datetime, float]]:
        """è¼‰å…¥ CSV æ•¸æ“š"""
        data = []
        try:
            df = pd.read_csv(csv_file)
            for _, row in df.iterrows():
                timestamp = datetime.strptime(row['æ™‚é–“'], '%Y-%m-%d %H:%M:%S')
                value = float(row.iloc[1])  # ç¬¬äºŒåˆ—æ˜¯æ•¸å€¼
                data.append((timestamp.timestamp(), value))
        except Exception as e:
            logger.error(f"è¼‰å…¥ CSV æ–‡ä»¶å¤±æ•— {csv_file}: {e}")
        
        return data
    
    def _load_average_data(self, avg_file: Path) -> Dict[str, Any]:
        """è¼‰å…¥å¹³å‡å€¼æ•¸æ“š"""
        averages = {}
        try:
            df = pd.read_csv(avg_file)
            for _, row in df.iterrows():
                gpu_name = row['gpu']
                averages[gpu_name] = {
                    'usage': float(row['usage']),
                    'vram': float(row['vram']),
                    'user': row['user']
                }
        except Exception as e:
            logger.error(f"è¼‰å…¥å¹³å‡å€¼æ–‡ä»¶å¤±æ•— {avg_file}: {e}")
        
        return averages
    
    def _calculate_gpu_statistics(self, gpu_data: Dict[str, Any]) -> Dict[str, Any]:
        """è¨ˆç®—å–®å€‹ GPU çš„çµ±è¨ˆè³‡è¨Š"""
        stats = {
            'utilization': None,
            'vram': None
        }
        
        # è™•ç†ä½¿ç”¨ç‡æ•¸æ“š
        if 'utilization' in gpu_data and gpu_data['utilization']:
            values = [val for _, val in gpu_data['utilization']]
            if values:
                stats['utilization'] = {
                    'count': len(values),
                    'mean': mean(values),
                    'median': median(values),
                    'std': stdev(values) if len(values) > 1 else 0,
                    'min': min(values),
                    'max': max(values),
                    'values': values
                }
        
        # è™•ç† VRAM æ•¸æ“š
        if 'vram' in gpu_data and gpu_data['vram']:
            values = [val for _, val in gpu_data['vram']]
            if values:
                stats['vram'] = {
                    'count': len(values),
                    'mean': mean(values),
                    'median': median(values),
                    'std': stdev(values) if len(values) > 1 else 0,
                    'min': min(values),
                    'max': max(values),
                    'values': values
                }
        
        return stats
    
    def _calculate_trend(self, values: List[float]) -> Dict[str, Any]:
        """è¨ˆç®—è¶¨å‹¢ï¼ˆç°¡å–®ç·šæ€§å›æ­¸ï¼‰"""
        if len(values) < 2:
            return {'trend': 'insufficient_data'}
        
        n = len(values)
        x = list(range(n))
        
        # è¨ˆç®—ç·šæ€§å›æ­¸
        x_mean = mean(x)
        y_mean = mean(values)
        
        numerator = sum((x[i] - x_mean) * (values[i] - y_mean) for i in range(n))
        denominator = sum((x[i] - x_mean) ** 2 for i in range(n))
        
        if denominator == 0:
            slope = 0
        else:
            slope = numerator / denominator
        
        # åˆ¤æ–·è¶¨å‹¢
        if slope > 0.5:
            trend = 'increasing'
        elif slope < -0.5:
            trend = 'decreasing'
        else:
            trend = 'stable'
        
        return {
            'trend': trend,
            'slope': slope,
            'start_value': values[0],
            'end_value': values[-1],
            'change_percent': ((values[-1] - values[0]) / values[0] * 100) if values[0] != 0 else 0
        }
    
    def _generate_recommendations(self, report: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆä½¿ç”¨å»ºè­°"""
        recommendations = []
        
        overall_stats = report['summary']['overall_stats']
        
        # åŸºæ–¼æ•´é«”ä½¿ç”¨ç‡çš„å»ºè­°
        if overall_stats['avg_utilization'] > 90:
            recommendations.append("ğŸ”´ æ•´é«” GPU ä½¿ç”¨ç‡éé«˜ï¼Œå»ºè­°è€ƒæ…®å¢åŠ è¨ˆç®—è³‡æº")
        elif overall_stats['avg_utilization'] < 30:
            recommendations.append("ğŸŸ¢ GPU ä½¿ç”¨ç‡è¼ƒä½ï¼Œè³‡æºåˆ©ç”¨æ•ˆç‡æœ‰æå‡ç©ºé–“")
        
        # åŸºæ–¼ VRAM ä½¿ç”¨ç‡çš„å»ºè­°
        if overall_stats['avg_vram'] > 85:
            recommendations.append("ğŸŸ¡ VRAM ä½¿ç”¨ç‡è¼ƒé«˜ï¼Œå»ºè­°ç›£æ§è¨˜æ†¶é«”æ´©æ¼")
        
        # åŸºæ–¼ç¯€é»ä½¿ç”¨çš„å»ºè­°
        node_utilizations = []
        for node_name, node_summary in report['summary']['node_summaries'].items():
            node_utilizations.append((node_name, node_summary['avg_utilization']))
        
        # æ‰¾å‡ºä½¿ç”¨ç‡å·®ç•°è¼ƒå¤§çš„ç¯€é»
        if len(node_utilizations) > 1:
            utilizations = [util for _, util in node_utilizations]
            max_util = max(utilizations)
            min_util = min(utilizations)
            
            if max_util - min_util > 40:
                recommendations.append("âš–ï¸ ç¯€é»é–“è² è¼‰ä¸å‡è¡¡ï¼Œå»ºè­°é‡æ–°åˆ†é…å·¥ä½œè² è¼‰")
        
        return recommendations